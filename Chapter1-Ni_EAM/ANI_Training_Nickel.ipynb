{"cells":[{"cell_type":"markdown","id":"0654077e","metadata":{"id":"0654077e"},"source":["::## ANI Model Training for Metal\n","\n"]},{"cell_type":"markdown","id":"59352a83","metadata":{"id":"59352a83"},"source":["### Step 1: Installing TorchANI\n","\n","First, we need to install TorchANI. Since the different cell size data are generated with the PBC conditions. During the data loading, this should appropriately be handled.\n","\n","The original TorchANI code does not provide a function that can handle different cell sizes during the training.\n","\n","We need to download a customized version for this tutorial.\n","\n"]},{"cell_type":"code","execution_count":1,"id":"ee92e4ea","metadata":{"id":"ee92e4ea","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711214641216,"user_tz":240,"elapsed":21142,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}},"outputId":"4a86306c-e813-4d2b-d1a4-6238ffef25bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/gsjung0419/torchani_gs.git@min-cell\n","  Cloning https://github.com/gsjung0419/torchani_gs.git (to revision min-cell) to /tmp/pip-req-build-rpiflsdw\n","  Running command git clone --filter=blob:none --quiet https://github.com/gsjung0419/torchani_gs.git /tmp/pip-req-build-rpiflsdw\n","  Running command git checkout -b min-cell --track origin/min-cell\n","  Switched to a new branch 'min-cell'\n","  Branch 'min-cell' set up to track remote branch 'min-cell' from 'origin'.\n","  Resolved https://github.com/gsjung0419/torchani_gs.git to commit a941e6b79fc39e5ff305fcdbfd01c52f4cbbb6cf\n","  Running command git submodule update --init --recursive -q\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchani==0.1.dev436+ga941e6b) (2.2.1+cu121)\n","Requirement already satisfied: lark-parser in /usr/local/lib/python3.10/dist-packages (from torchani==0.1.dev436+ga941e6b) (0.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchani==0.1.dev436+ga941e6b) (2.31.0)\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.10/dist-packages (from torchani==0.1.dev436+ga941e6b) (7.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata->torchani==0.1.dev436+ga941e6b) (3.18.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchani==0.1.dev436+ga941e6b) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchani==0.1.dev436+ga941e6b) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchani==0.1.dev436+ga941e6b) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchani==0.1.dev436+ga941e6b) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchani==0.1.dev436+ga941e6b) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchani==0.1.dev436+ga941e6b) (12.4.99)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchani==0.1.dev436+ga941e6b) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchani==0.1.dev436+ga941e6b) (1.3.0)\n"]}],"source":["!pip install git+https://github.com/gsjung0419/torchani_gs.git@min-cell"]},{"cell_type":"markdown","id":"bbcf914b","metadata":{"id":"bbcf914b"},"source":["### Step 2: Importing Required Libraries\n","\n","In this step, we import the necessary libraries for our task.\n","\n","Also, let's utilize GPU.\n","\n","In the Runtime menu, click 'change runtime type', you may need to restart the session and download the torchani again."]},{"cell_type":"code","execution_count":4,"id":"581d6b9b","metadata":{"id":"581d6b9b","executionInfo":{"status":"ok","timestamp":1711214717771,"user_tz":240,"elapsed":248,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ed88747d-4731-4430-b75a-a1507adb6cba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Check the device is cuda, otherwier, it take time cuda\n"]}],"source":["import torch\n","import torchani\n","import os\n","import math\n","import torch.utils.tensorboard\n","import tqdm\n","\n","# helper function to convert energy unit from Hartree to kcal/mol\n","from torchani.units import hartree2kcalmol\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Check the device is cuda, otherwier, it take time\", device)"]},{"cell_type":"markdown","id":"24e1b29e","metadata":{"id":"24e1b29e"},"source":["### Step 3: Loading the Dataset\n","\n","I recommand to use your own google drive to setup your local drive to download files and save the log file for running."]},{"cell_type":"code","execution_count":5,"id":"S04m5lIKQBUt","metadata":{"id":"S04m5lIKQBUt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b10bdb76-ac10-434a-bd89-c1c0d7ed73a2","executionInfo":{"status":"ok","timestamp":1711214721668,"user_tz":240,"elapsed":1597,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Please decide where to run. You should provide the path of google drive where you are running this tutorial."],"metadata":{"id":"BF0i-R2CtTYm"},"id":"BF0i-R2CtTYm"},{"cell_type":"code","execution_count":6,"id":"HrGSyVuzQi1e","metadata":{"id":"HrGSyVuzQi1e","colab":{"base_uri":"https://localhost:8080/"},"outputId":"af96fbd7-4e76-40b9-da9f-b14ec10d142f","executionInfo":{"status":"ok","timestamp":1711214723638,"user_tz":240,"elapsed":210,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ANI_Tutorials/Metal\n"]}],"source":["%cd /content/drive/MyDrive/ANI_Tutorials/Metal"]},{"cell_type":"code","execution_count":7,"id":"2ae83a8f","metadata":{"id":"2ae83a8f","executionInfo":{"status":"ok","timestamp":1711214725539,"user_tz":240,"elapsed":331,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"outputs":[],"source":["try:\n","    path = os.path.dirname(os.path.realpath(__file__))\n","except NameError:\n","    path = os.getcwd()\n","\n","#This file defines the energy shift for each atom species\n","sae_file = os.path.join(path, 'sae_linfit_dftb.data')\n","\n","#This file defines the BP symmetry functions\n","const_file = os.path.join(path, 'rC.params')\n","\n","consts = torchani.neurochem.Constants(const_file)\n","aev_computer = torchani.AEVComputer(**consts)\n","\n","#Set up the minimum size of cell in your training data.\n","#This is based on the customized version. A better version for handling virial stress terms will be opened soon.\n","min_cell=torch.tensor([[10.0,0,0],[0,10.0,0],[0,0,10.0]],requires_grad=True,dtype=torch.float64,device=device)\n","aev_computer.setMinCell(min_cell)\n","\n","#Note that the atom is set to 'C' for the simplicity but you can change it to any atom name.\n","#This is a just name, does not affect your trainning.\n","#But once you change it, following code should be consistent.\n","energy_shifter = torchani.neurochem.load_sae(sae_file)\n","species_order = ['C']"]},{"cell_type":"markdown","id":"433e66ec","metadata":{"id":"433e66ec"},"source":["### Step 4: Data Preprocessing\n","\n","In this step, we define the batchsize.\n","\n","You can change and test.  \n","\n","Training/Validation sets are already given"]},{"cell_type":"code","execution_count":8,"id":"48a1d195","metadata":{"id":"48a1d195","executionInfo":{"status":"ok","timestamp":1711214728250,"user_tz":240,"elapsed":228,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"outputs":[],"source":["trpath = os.path.join(path, 'train.h5')\n","valpath = os.path.join(path, 'validation.h5')\n","batch_size = 64 #second epoch"]},{"cell_type":"markdown","source":["Please install hdf5-tools to check the data \"*.h5\""],"metadata":{"id":"5NEyzlBwvFdG"},"id":"5NEyzlBwvFdG"},{"cell_type":"code","source":["!apt-get install -y hdf5-tools"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbilbIWpvEHD","executionInfo":{"status":"ok","timestamp":1711214731942,"user_tz":240,"elapsed":1920,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}},"outputId":"0b2426b5-2a5c-4659-f1ae-6f0bdac288fd"},"id":"CbilbIWpvEHD","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","hdf5-tools is already the newest version (1.10.7+repack-4ubuntu2).\n","0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"]}]},{"cell_type":"code","source":["!h5ls -rf train.h5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KBQViB8QuugW","executionInfo":{"status":"ok","timestamp":1711214759382,"user_tz":240,"elapsed":257,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}},"outputId":"e3f93b88-8a0f-410e-d9ec-cb54282c564a"},"id":"KBQViB8QuugW","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/                        Group\n","/mols                    Group\n","/mols/AC0                Group\n","/mols/AC0/cell           Dataset {68, 3, 3}\n","/mols/AC0/coordinates    Dataset {68, 32, 3}\n","/mols/AC0/energies       Dataset {68}\n","/mols/AC0/forces         Dataset {68, 32, 3}\n","/mols/AC0/species        Dataset {32}\n","/mols/AC0/virial         Dataset {68, 6}\n","/mols/AC1                Group\n","/mols/AC1/cell           Dataset {136, 3, 3}\n","/mols/AC1/coordinates    Dataset {136, 32, 3}\n","/mols/AC1/energies       Dataset {136}\n","/mols/AC1/forces         Dataset {136, 32, 3}\n","/mols/AC1/species        Dataset {32}\n","/mols/AC1/virial         Dataset {136, 6}\n","/mols/AC2                Group\n","/mols/AC2/cell           Dataset {59, 3, 3}\n","/mols/AC2/coordinates    Dataset {59, 32, 3}\n","/mols/AC2/energies       Dataset {59}\n","/mols/AC2/forces         Dataset {59, 32, 3}\n","/mols/AC2/species        Dataset {32}\n","/mols/AC2/virial         Dataset {59, 6}\n","/mols/AC3                Group\n","/mols/AC3/cell           Dataset {116, 3, 3}\n","/mols/AC3/coordinates    Dataset {116, 32, 3}\n","/mols/AC3/energies       Dataset {116}\n","/mols/AC3/forces         Dataset {116, 32, 3}\n","/mols/AC3/species        Dataset {32}\n","/mols/AC3/virial         Dataset {116, 6}\n","/mols/AC4                Group\n","/mols/AC4/cell           Dataset {181, 3, 3}\n","/mols/AC4/coordinates    Dataset {181, 32, 3}\n","/mols/AC4/energies       Dataset {181}\n","/mols/AC4/forces         Dataset {181, 32, 3}\n","/mols/AC4/species        Dataset {32}\n","/mols/AC4/virial         Dataset {181, 6}\n","/mols/AC5                Group\n","/mols/AC5/cell           Dataset {178, 3, 3}\n","/mols/AC5/coordinates    Dataset {178, 32, 3}\n","/mols/AC5/energies       Dataset {178}\n","/mols/AC5/forces         Dataset {178, 32, 3}\n","/mols/AC5/species        Dataset {32}\n","/mols/AC5/virial         Dataset {178, 6}\n","/mols/AC6                Group\n","/mols/AC6/cell           Dataset {117, 3, 3}\n","/mols/AC6/coordinates    Dataset {117, 32, 3}\n","/mols/AC6/energies       Dataset {117}\n","/mols/AC6/forces         Dataset {117, 32, 3}\n","/mols/AC6/species        Dataset {32}\n","/mols/AC6/virial         Dataset {117, 6}\n","/mols/AC7                Group\n","/mols/AC7/cell           Dataset {154, 3, 3}\n","/mols/AC7/coordinates    Dataset {154, 32, 3}\n","/mols/AC7/energies       Dataset {154}\n","/mols/AC7/forces         Dataset {154, 32, 3}\n","/mols/AC7/species        Dataset {32}\n","/mols/AC7/virial         Dataset {154, 6}\n","/mols/Rd                 Group\n","/mols/Rd/cell            Dataset {1592, 3, 3}\n","/mols/Rd/coordinates     Dataset {1592, 32, 3}\n","/mols/Rd/energies        Dataset {1592}\n","/mols/Rd/forces          Dataset {1592, 32, 3}\n","/mols/Rd/species         Dataset {32}\n","/mols/Rd/virial          Dataset {1592, 6}\n"]}]},{"cell_type":"markdown","source":["Data loading for batch trainning.\n","\n","Note that additional_properties you can define to load it in addition to 'energy,'  and 'coordinates'."],"metadata":{"id":"T7YEP6dEvWtZ"},"id":"T7YEP6dEvWtZ"},{"cell_type":"code","source":["training = torchani.data.load(\n","    trpath,\n","    additional_properties=('forces','cell')\n",").subtract_self_energies(energy_shifter, species_order).species_to_indices(species_order).shuffle()\n","\n","validation = torchani.data.load(\n","    valpath,\n","    additional_properties=('forces','cell')\n",").subtract_self_energies(energy_shifter, species_order).species_to_indices(species_order).shuffle()\n","\n","training = training.collate(batch_size).cache()\n","validation = validation.collate(batch_size).cache()"],"metadata":{"id":"_cFZ67mzckyI","executionInfo":{"status":"ok","timestamp":1711214764089,"user_tz":240,"elapsed":1611,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"id":"_cFZ67mzckyI","execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Here, we define PBC and AEV dimensions and network"],"metadata":{"id":"W0afbRKDjUfJ"},"id":"W0afbRKDjUfJ"},{"cell_type":"code","source":["pbc = torch.tensor([1,1,1],dtype=torch.bool,device=device)\n","aev_dim = aev_computer.aev_length\n","\n","#Note that the original ANI potential utilizes CELU for the activation function.\n","#From the tests, we found that GELU works better for force and stress.\n","C_network = torch.nn.Sequential(\n","    torch.nn.Linear(aev_dim, 224),\n","    torch.nn.GELU(),\n","    torch.nn.Linear(224, 192),\n","    torch.nn.GELU(),\n","    torch.nn.Linear(192, 160),\n","    torch.nn.GELU(),\n","    torch.nn.Linear(160, 1)\n",")\n","\n","#Define Neural Network\n","nn = torchani.ANIModel([C_network])\n"],"metadata":{"id":"HGqS-g2_EIDd","executionInfo":{"status":"ok","timestamp":1711214770158,"user_tz":240,"elapsed":251,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"id":"HGqS-g2_EIDd","execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["Here, we initialize all the parameters."],"metadata":{"id":"SWyLL3MNwJoz"},"id":"SWyLL3MNwJoz"},{"cell_type":"code","source":["def init_params(m):\n","    if isinstance(m, torch.nn.Linear):\n","        torch.nn.init.kaiming_normal_(m.weight, a=1.0)\n","        torch.nn.init.zeros_(m.bias)\n","\n","nn.apply(init_params)"],"metadata":{"id":"9DHxo2yOyytv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711214773689,"user_tz":240,"elapsed":265,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}},"outputId":"eb9a7384-fc80-4ea9-e3d3-683be99dafaf"},"id":"9DHxo2yOyytv","execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ANIModel(\n","  (0): Sequential(\n","    (0): Linear(in_features=54, out_features=224, bias=True)\n","    (1): GELU(approximate='none')\n","    (2): Linear(in_features=224, out_features=192, bias=True)\n","    (3): GELU(approximate='none')\n","    (4): Linear(in_features=192, out_features=160, bias=True)\n","    (5): GELU(approximate='none')\n","    (6): Linear(in_features=160, out_features=1, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["model = torchani.nn.Sequential(aev_computer, nn).to(device)"],"metadata":{"id":"pS33uwRSjgj4","executionInfo":{"status":"ok","timestamp":1711214777761,"user_tz":240,"elapsed":222,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"id":"pS33uwRSjgj4","execution_count":14,"outputs":[]},{"cell_type":"markdown","id":"cb33d7ec","metadata":{"id":"cb33d7ec"},"source":["### Step 7: Training the Model\n","\n","Here we define scheduler.\n","\n","For the weights, we utilize Adam Optimizer.\n","For the bias, Stochastic Gradient Descendent (SGD) Algorithm is utilized."]},{"cell_type":"code","source":["AdamW = torch.optim.AdamW([\n","    # C networks\n","    {'params': [C_network[0].weight]},\n","    {'params': [C_network[2].weight], 'weight_decay': 0.00001},\n","    {'params': [C_network[4].weight], 'weight_decay': 0.000001},\n","    {'params': [C_network[6].weight]},\n","])\n","\n","SGD = torch.optim.SGD([\n","    # C networks\n","    {'params': [C_network[0].bias]},\n","    {'params': [C_network[2].bias]},\n","    {'params': [C_network[4].bias]},\n","    {'params': [C_network[6].bias]},\n","], lr=1e-4)\n","\n","#This schedule include the learning rate change.\n","#In this example, you may not observe learning-rate chages.\n","AdamW_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(AdamW, factor=0.5, patience=100, threshold=0)\n","SGD_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(SGD, factor=0.5, patience=100, threshold=0)"],"metadata":{"id":"TkXyL8RrymmO","executionInfo":{"status":"ok","timestamp":1711214781234,"user_tz":240,"elapsed":1169,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"id":"TkXyL8RrymmO","execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["Define check points and the file name for the parameters."],"metadata":{"id":"pPoiM8XPxHJD"},"id":"pPoiM8XPxHJD"},{"cell_type":"code","source":["latest_checkpoint = 'force-training-latest.pt'\n","if os.path.isfile(latest_checkpoint):\n","    checkpoint = torch.load(latest_checkpoint)\n","    nn.load_state_dict(checkpoint['nn'])\n","    AdamW.load_state_dict(checkpoint['AdamW'])\n","    SGD.load_state_dict(checkpoint['SGD'])\n","    AdamW_scheduler.load_state_dict(checkpoint['AdamW_scheduler'])\n","    SGD_scheduler.load_state_dict(checkpoint['SGD_scheduler'])"],"metadata":{"id":"-ZosWJ4QE6rV","executionInfo":{"status":"ok","timestamp":1711214783912,"user_tz":240,"elapsed":208,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"id":"-ZosWJ4QE6rV","execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Define the validate() function to measure the performance of the trained model for the validation sets."],"metadata":{"id":"h8fOrTfjxVfc"},"id":"h8fOrTfjxVfc"},{"cell_type":"code","source":["def validate():\n","    # run validation\n","    mse_sum = torch.nn.MSELoss(reduction='sum')\n","    total_mse = 0.0\n","    count = 0\n","    total_msef =0.0\n","\n","    model.train(False)\n","    for properties in validation:\n","      species = properties['species'].to(device)\n","      #coordinates = properties['coordinates'].to(device).float()\n","      coordinates = properties['coordinates'].to(device).float().requires_grad_(True)\n","      true_energies = properties['energies'].to(device).float()\n","      true_forces = properties['forces'].to(device).float()\n","      cell = properties['cell'].to(device).float()\n","      _, predicted_energies = model((species, coordinates),cell,pbc)\n","      forces = -torch.autograd.grad(predicted_energies.sum(), coordinates)[0]\n","      total_mse += mse_sum(predicted_energies, true_energies).item()\n","      total_msef += mse_sum(true_forces, forces).item()\n","      count += predicted_energies.shape[0]\n","\n","\n","    model.train(True)\n","    return hartree2kcalmol(math.sqrt(total_mse / count)),hartree2kcalmol(math.sqrt(total_msef/count))"],"metadata":{"id":"wAh-BAY8jwBo","executionInfo":{"status":"ok","timestamp":1711215729283,"user_tz":240,"elapsed":432,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"id":"wAh-BAY8jwBo","execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["Define the tensorboard to write the log file to check the trainning."],"metadata":{"id":"RfOwX3KSxg8_"},"id":"RfOwX3KSxg8_"},{"cell_type":"code","source":["tensorboard = torch.utils.tensorboard.SummaryWriter()"],"metadata":{"id":"RTVewsb8jyvK","executionInfo":{"status":"ok","timestamp":1711214789140,"user_tz":240,"elapsed":231,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"id":"RTVewsb8jyvK","execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["Here, we deifne the loss function.\n","\n","The force components for the training is set 0.1.\n","\n","Only RMSE of energy was check for the best model.\n","\n","There can be different setting you may try to find."],"metadata":{"id":"FW5IiCykxw6O"},"id":"FW5IiCykxw6O"},{"cell_type":"code","source":["!rm *.pt\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jgKGoEbFyUya","executionInfo":{"status":"ok","timestamp":1711205592299,"user_tz":240,"elapsed":378,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}},"outputId":"72269c16-4506-4f09-d99a-eede55a91341"},"id":"jgKGoEbFyUya","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove '*.pt': No such file or directory\n","ANI_Training.ipynb     rC.params  sae_linfit_dftb.data\tvalidation.h5\n","nnp_training_force.py  runs\t  train.h5\n"]}]},{"cell_type":"code","source":["mse = torch.nn.MSELoss(reduction='none')\n","\n","print(\"training starting from epoch\", AdamW_scheduler.last_epoch + 1)\n","\n","#Define the maximum number of epoch\n","max_epochs = 303\n","\n","#Early_stopping but usually not activated.\n","early_stopping_learning_rate = 1.0E-5\n","\n","force_coefficient = 0.2  # controls the importance of energy loss vs force loss\n","\n","#The best model check point\n","best_model_checkpoint = 'force-training-best.pt'\n","\n","for _ in range(AdamW_scheduler.last_epoch + 1, max_epochs):\n","    rmse,rmse_f = validate()\n","\n","    print('RMSE of Energy and Forces ', rmse, rmse_f, 'at epoch', AdamW_scheduler.last_epoch + 1)\n","\n","    learning_rate = AdamW.param_groups[0]['lr']\n","\n","    if learning_rate < early_stopping_learning_rate:\n","        break\n","\n","    # checkpoint\n","    if AdamW_scheduler.is_better(rmse, AdamW_scheduler.best):\n","        torch.save(nn.state_dict(), best_model_checkpoint)\n","\n","    AdamW_scheduler.step(rmse)\n","    SGD_scheduler.step(rmse)\n","\n","    # This allows us to check the history of training by tensorboad\n","    tensorboard.add_scalar('validation_rmse', rmse, AdamW_scheduler.last_epoch)\n","    tensorboard.add_scalar('best_validation_rmse', AdamW_scheduler.best, AdamW_scheduler.last_epoch)\n","    tensorboard.add_scalar('learning_rate', learning_rate, AdamW_scheduler.last_epoch)\n","\n","\n","    # Besides being stored in x, species and coordinates are also stored in y.\n","    # So here, for simplicity, we just ignore the x and use y for everything.\n","    for i, properties in tqdm.tqdm(\n","        enumerate(training),\n","        total=len(training),\n","        desc=\"epoch {}\".format(AdamW_scheduler.last_epoch)\n","    ):\n","        species = properties['species'].to(device)\n","        coordinates = properties['coordinates'].to(device).float().requires_grad_(True)\n","        true_energies = properties['energies'].to(device).float()\n","        true_forces = properties['forces'].to(device).float()\n","        cell = properties['cell'].to(device).float()\n","        num_atoms = (species >= 0).sum(dim=1, dtype=true_energies.dtype)\n","        _, predicted_energies = model((species, coordinates),cell,pbc)\n","\n","        # We can use torch.autograd.grad to compute force. Remember to\n","        # create graph so that the loss of the force can contribute to\n","        # the gradient of parameters, and also to retain graph so that\n","        # we can backward through it a second time when computing gradient\n","        # w.r.t. parameters.\n","        forces = -torch.autograd.grad(predicted_energies.sum(), coordinates, create_graph=True, retain_graph=True)[0]\n","\n","        # Now the total loss has two parts, energy loss and force loss\n","        energy_loss = (mse(predicted_energies, true_energies) / num_atoms.sqrt()).mean()\n","        force_loss = (mse(true_forces, forces).sum(dim=(1, 2)) / num_atoms).mean()\n","        loss = energy_loss + force_coefficient * force_loss\n","\n","        AdamW.zero_grad()\n","        SGD.zero_grad()\n","        loss.backward()\n","        AdamW.step()\n","        SGD.step()\n","\n","        # write current batch loss to TensorBoard\n","        tensorboard.add_scalar('Energy_loss',energy_loss,AdamW_scheduler.last_epoch)\n","        tensorboard.add_scalar('Force_loss',force_loss,AdamW_scheduler.last_epoch)\n","        tensorboard.add_scalar('batch_loss',loss, AdamW_scheduler.last_epoch * len(training) + i)\n","\n","    torch.save({\n","        'nn': nn.state_dict(),\n","        'AdamW': AdamW.state_dict(),\n","        'SGD': SGD.state_dict(),\n","        'AdamW_scheduler': AdamW_scheduler.state_dict(),\n","        'SGD_scheduler': SGD_scheduler.state_dict(),\n","    }, latest_checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tNSGgCAnEHs5","outputId":"74ca6c9b-5004-4428-bff1-9a673425152b","executionInfo":{"status":"ok","timestamp":1711215741894,"user_tz":240,"elapsed":235,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"id":"tNSGgCAnEHs5","execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["training starting from epoch 303\n"]}]},{"cell_type":"markdown","id":"74d2ec11","metadata":{"id":"74d2ec11"},"source":["### Step 8: Evaluating the Model\n","\n","After training, we evaluate the model's performance on the validation set."]},{"cell_type":"code","source":["def LoadANI(path,mname):\n","    sae_file = os.path.join(path, 'sae_linfit_dftb.data')  # noqa: E501\n","    const_file = os.path.join(path, 'rC.params')\n","\n","    consts = torchani.neurochem.Constants(const_file)\n","    aev_computer = torchani.AEVComputer(**consts)\n","\n","    #min_cell=torch.tensor([[10.0,0,0],[0,10.0,0],[0,0,10.0]],requires_grad=True,dtype=torch.float64,device=device)\n","    min_cell=torch.tensor([[10.0,0,0],[0,10.0,0],[0,0,10.0]],dtype=torch.float64,device=device)\n","    pbc = torch.tensor([1,1,1],dtype=torch.bool,device=device)\n","    aev_computer.setMinCell(min_cell)\n","\n","    energy_shifter = torchani.neurochem.load_sae(sae_file)\n","    species_order = ['C']\n","    aev_dim = aev_computer.aev_length\n","    C_network = torch.nn.Sequential(\n","        torch.nn.Linear(aev_dim, 224),\n","        torch.nn.GELU(),\n","        torch.nn.Linear(224, 192),\n","        torch.nn.GELU(),\n","        torch.nn.Linear(192, 160),\n","        torch.nn.GELU(),\n","        torch.nn.Linear(160, 1)\n","    )\n","\n","    nn = torchani.ANIModel([C_network])\n","    ptname = mname+'.pt'\n","    #nn.load_state_dict(torch.load('force-training-best.pt',map_location='cpu'))\n","    nn.load_state_dict(torch.load(ptname,map_location='cpu'))\n","    model = torchani.nn.Sequential(aev_computer, nn, energy_shifter).to(device)\n","\n","    return model"],"metadata":{"id":"YIirOP9e1fdr","executionInfo":{"status":"ok","timestamp":1711215747080,"user_tz":240,"elapsed":227,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"id":"YIirOP9e1fdr","execution_count":43,"outputs":[]},{"cell_type":"code","source":["bestmodel = LoadANI('./','force-training-best')"],"metadata":{"id":"pvvsqZez2Te-","executionInfo":{"status":"ok","timestamp":1711215750078,"user_tz":240,"elapsed":698,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"id":"pvvsqZez2Te-","execution_count":44,"outputs":[]},{"cell_type":"code","source":["def evaluate(dataset):\n","    # run validation\n","    mse_sum = torch.nn.L1Loss(reduction='sum')\n","    total_mse = 0.0\n","    count = 0\n","\n","    model.train(False)\n","    with torch.no_grad():\n","        for properties in dataset:\n","            species = properties['species'].to(device)\n","            coordinates = properties['coordinates'].to(device).float()\n","            true_energies = properties['energies'].to(device).float()\n","            true_forces = properties['forces'].to(device).float()\n","            cell = properties['cell'].to(device).float()\n","            _, predicted_energies = bestmodel((species, coordinates),cell,pbc)\n","\n","            total_mse += mse_sum(predicted_energies, true_energies).item()\n","            count += predicted_energies.shape[0]\n","\n","    model.train(True)\n","    return hartree2kcalmol(total_mse / count)"],"metadata":{"id":"mA1cKla53Mhi","executionInfo":{"status":"ok","timestamp":1711215767392,"user_tz":240,"elapsed":253,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}}},"id":"mA1cKla53Mhi","execution_count":45,"outputs":[]},{"cell_type":"code","source":["MAE=evaluate(training)*0.043/32*1000 # divided by the number of atoms. the unit to meV/atom\n","print(\"The error of training set (meV/atom)\", MAE)\n","MAE=evaluate(validation)*0.043/32*1000 # divided by the number of atoms. the unit to meV/atom\n","print(\"The error of validation set (meV/atom)\", MAE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kv9mMBmR2tR-","executionInfo":{"status":"ok","timestamp":1711215805441,"user_tz":240,"elapsed":703,"user":{"displayName":"Gang Seob Jung","userId":"15714856675082356055"}},"outputId":"ffad766a-c7db-4287-a0c2-6d1011f33a0f"},"id":"Kv9mMBmR2tR-","execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["The error of training set (meV/atom) 3.2101794949590556\n","The error of validation set (meV/atom) 1.6875436915885036\n"]}]},{"cell_type":"markdown","source":["\n","If you think this tutorial is useful, consider cite the following references:\n","\n","References\n","1. The function for different cell sizes was developed in this study:\n","\n","  Jung, G. S., Myung, H., & Irle, S. (2023). Artificial neural network potentials for mechanics and fracture dynamics of two-dimensional crystals. Machine Learning: Science and Technology, 4(3), 035001.\n","\n","2. The data set were prepared by the study:\n","\n"," Jung, G. S., Lee, S., & Choi, J. Y. (2023). Data Distillation for Neural Network Potentials toward Foundational Dataset. arXiv preprint arXiv:2311.05407.\n","\n"," using active learning tool developed by the study:\n"," Jung, G. S., Choi, J. Y., & Lee, S. M. (2024). Active learning of neural network potentials for rare events. Digital Discovery.\n","\n","3. The original code of TorchANI developed by the study:\n","\n","  Gao, X., Ramezanghorbani, F., Isayev, O., Smith, J. S., & Roitberg, A. E. (2020). TorchANI: A free and open source PyTorch-based deep learning implementation of the ANI neural network potentials. Journal of chemical information and modeling, 60(7), 3408-3415.\n","\n"],"metadata":{"id":"uABAqN73grE-"},"id":"uABAqN73grE-"},{"cell_type":"markdown","source":["Load best model for validation set."],"metadata":{"id":"roob3eCKUrfG"},"id":"roob3eCKUrfG"}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}